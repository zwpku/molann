{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d607a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4a8aaf4c3c497f8e5a3f9141eda637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math \n",
    "import random\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import dihedrals, rms, align\n",
    "import nglview as nv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f43f1",
   "metadata": {},
   "source": [
    "## Part 1: prepare MD data\n",
    "#### 1.1. show some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9629f51a",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MD system:\n",
      "\tno. of atoms: 22\n",
      "\tno. of residues: 3\n",
      "\n",
      "Detailed atom information:\n",
      "     id  name type    mass resid resname\n",
      "0    1  1HH3    H   1.008     1     ACE\n",
      "1    2   CH3    C  12.011     1     ACE\n",
      "2    3  2HH3    H   1.008     1     ACE\n",
      "3    4  3HH3    H   1.008     1     ACE\n",
      "4    5     C    C  12.011     1     ACE\n",
      "5    6     O    O  15.999     1     ACE\n",
      "6    7     N    N  14.007     2     ALA\n",
      "7    8     H    H   1.008     2     ALA\n",
      "8    9    CA    C  12.011     2     ALA\n",
      "9   10    HA    H   1.008     2     ALA\n",
      "10  11    CB    C  12.011     2     ALA\n",
      "11  12   1HB    H   1.008     2     ALA\n",
      "12  13   2HB    H   1.008     2     ALA\n",
      "13  14   3HB    H   1.008     2     ALA\n",
      "14  15     C    C  12.011     2     ALA\n",
      "15  16     O    O  15.999     2     ALA\n",
      "16  17     N    N  14.007     3     NME\n",
      "17  18     H    H   1.008     3     NME\n",
      "18  19   CH3    C  12.011     3     NME\n",
      "19  20  1HH3    H   1.008     3     NME\n",
      "20  21  2HH3    H   1.008     3     NME\n",
      "21  22  3HH3    H   1.008     3     NME\n",
      "\n",
      "Summary:\n",
      "   type  counts\n",
      "0    H      12\n",
      "1    C       6\n",
      "2    O       2\n",
      "3    N       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/miniconda3/lib/python3.9/site-packages/MDAnalysis/topology/PDBParser.py:317: UserWarning: Element information is missing, elements attribute will not be populated. If needed these can be guessed using MDAnalysis.topology.guessers.\n",
      "  warnings.warn(\"Element information is missing, elements attribute \"\n"
     ]
    }
   ],
   "source": [
    "sys_name = 'AlanineDipeptide'\n",
    "\n",
    "# name of PDB file\n",
    "pdb_filename = \"MD_samplers/AlanineDipeptideOpenMM/vacuum.pdb\"\n",
    "# name of DCD file\n",
    "output_path = 'MD_samplers/allegro-data/working_dir/Langevin_working_dir' \n",
    "#output_path = './allegro-data/working_dir/Langevin_working_dir-test3-plumed/' \n",
    "traj_dcd_filename = '%s/traj.dcd' % output_path\n",
    "\n",
    "# load the reference configuration from the PDB file\n",
    "ref = mda.Universe(pdb_filename) \n",
    "\n",
    "atoms_info = pd.DataFrame(\n",
    "    np.array([ref.atoms.ids, ref.atoms.names, ref.atoms.types, ref.atoms.masses, ref.atoms.resids, ref.atoms.resnames]).T, \n",
    "    columns=['id', 'name', 'type', 'mass', 'resid', 'resname']\n",
    ")\n",
    "\n",
    "# print information of trajectory\n",
    "print ('\\nMD system:\\n\\\n",
    "\\tno. of atoms: {}\\n\\\n",
    "\\tno. of residues: {}\\n'.format(ref.trajectory.n_atoms, ref.residues.n_residues)\n",
    "      )\n",
    "print ('Detailed atom information:\\n', atoms_info)\n",
    "\n",
    "print ('\\nSummary:\\n', atoms_info['type'].value_counts().rename_axis('type').reset_index(name='counts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa901f",
   "metadata": {},
   "source": [
    "#### 1.2 load trajectory, and align with respect to refenrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4966333",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/miniconda3/lib/python3.9/site-packages/MDAnalysis/topology/PDBParser.py:317: UserWarning: Element information is missing, elements attribute will not be populated. If needed these can be guessed using MDAnalysis.topology.guessers.\n",
      "  warnings.warn(\"Element information is missing, elements attribute \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Task 1/2] load trajectory to numpy array...done.\n",
      "\n",
      "Trajectory Info:\n",
      "\tno. of frames in trajectory data: 50000\n",
      "\ttimestep: 1.0ps\n",
      "\ttime length: 49999.0ps\n",
      "\tshape of trajectory data array: torch.Size([50000, 22, 3])\n",
      "\n",
      "[Task 2/2] aligning by atoms:\n",
      "    id name type\n",
      "1    2  CH3    C\n",
      "4    5    C    C\n",
      "5    6    O    O\n",
      "6    7    N    N\n",
      "8    9   CA    C\n",
      "10  11   CB    C\n",
      "14  15    C    C\n",
      "15  16    O    O\n",
      "16  17    N    N\n",
      "18  19  CH3    C\n",
      "torch.Size([50000, 22, 3])\n",
      "\n",
      "[Task 2/2] done.\n"
     ]
    }
   ],
   "source": [
    "# define a class for aligning trajectory\n",
    "class Align(object):\n",
    "    def __init__(self, ref_pos, align_atom_indices):\n",
    "        self.atom_indices = align_atom_indices\n",
    "        self.ref_x = torch.from_numpy(ref_pos[align_atom_indices]).double()        \n",
    "        # shift reference state \n",
    "        ref_c = torch.mean(self.ref_x, 0) \n",
    "        self.ref_x = self.ref_x - ref_c\n",
    "        self.num_atoms = len(align_atom_indices) * 3\n",
    "        \n",
    "    def dist_to_ref(self, traj):\n",
    "        return torch.linalg.norm(torch.sub(traj[:,self.atom_indices,:], self.ref_x), dim=(1,2)).numpy()     \n",
    "            \n",
    "    def __call__(self, traj):    \n",
    "        traj_selected_atoms = traj[:, self.atom_indices, :]\n",
    "        # centers\n",
    "        x_c = torch.mean(traj_selected_atoms, 1, True)\n",
    "        # translation\n",
    "        x_notran = traj_selected_atoms - x_c \n",
    "        \n",
    "        xtmp = x_notran.permute((0,2,1))\n",
    "        prod = torch.matmul(xtmp, self.ref_x) # dimension: traj_length x 3 x 3\n",
    "        u, s, vh = torch.linalg.svd(prod)\n",
    "\n",
    "        diag_mat = torch.diag(torch.ones(3)).double().unsqueeze(0).repeat(traj.size(0), 1, 1)\n",
    "\n",
    "        sign_vec = torch.sign(torch.linalg.det(torch.matmul(u, vh))).detach()\n",
    "        diag_mat[:,2,2] = sign_vec\n",
    "\n",
    "        rotate_mat = torch.bmm(torch.bmm(u, diag_mat), vh)\n",
    "\n",
    "        return torch.matmul(traj-x_c, rotate_mat)     \n",
    "\n",
    "# load the trajectory data from DCD file\n",
    "u = mda.Universe(pdb_filename, traj_dcd_filename)\n",
    "\n",
    "print ('\\n[Task 1/2] load trajectory to numpy array...', end='')\n",
    "# load trajectory to torch tensor \n",
    "trajectory = torch.from_numpy(u.trajectory.timeseries(order='fac')).double()\n",
    "print ('done.')\n",
    "\n",
    "# print information of trajectory\n",
    "print ('\\nTrajectory Info:\\n\\\n",
    "\\tno. of frames in trajectory data: {}\\n\\\n",
    "\\ttimestep: {:.1f}ps\\n\\\n",
    "\\ttime length: {:.1f}ps\\n\\\n",
    "\\tshape of trajectory data array: {}'.format(u.trajectory.n_frames, \n",
    "                                  u.trajectory.time, \n",
    "                                  u.trajectory.totaltime,\n",
    "                                  trajectory.shape\n",
    "                                 )\n",
    "      )\n",
    "\n",
    "align_selector = \"type C or type O or type N\"\n",
    "selected_ids = u.select_atoms(align_selector).ids\n",
    "\n",
    "align_functor = Align(ref.atoms.positions, selected_ids-1)\n",
    "\n",
    "print ('\\n[Task 2/2] aligning by atoms:')\n",
    "print (atoms_info.loc[atoms_info['id'].isin(selected_ids)][['id','name', 'type']])\n",
    "\n",
    "head_frames = 5\n",
    "dist_list = align_functor.dist_to_ref(trajectory[:head_frames,:,:])\n",
    "trajectory = align_functor(trajectory)\n",
    "dist_list_aligned = align_functor.dist_to_ref(trajectory[:head_frames,:,:])\n",
    "\n",
    "\"\"\"\n",
    "#One could also use the alignment methods provided in MDAnalysis package \n",
    "rmsd_list = []\n",
    "for idx in range(head_frames):\n",
    "    rmsd_ret = rms.rmsd(trajectory[idx,selected_ids-1,:], ref_pos[selected_ids-1,:], superposition=False)\n",
    "    rmsd_list.append(rmsd_ret)\n",
    "\n",
    "align.AlignTraj(u,  # trajectory to align\n",
    "                ref,  # reference\n",
    "                select=align_selector,  # selection of atoms to align\n",
    "                filename=None,  # file to write the trajectory to\n",
    "                in_memory=True,\n",
    "                match_atoms=True,  # whether to match atoms based on mass\n",
    "               ).run()\n",
    "\n",
    "print ('\\n[Task 1/2] done.')\n",
    "\n",
    "rmsd_list_aligned = []\n",
    "for ts in u.trajectory[:head_frames]:\n",
    "    rmsd_ret = rms.rmsd(u.select_atoms(align_selector).positions, ref.select_atoms(align_selector).positions, superposition=False)\n",
    "    rmsd_list_aligned.append(rmsd_ret)\n",
    "\"\"\"\n",
    "\n",
    "print ('\\n[Task 2/2] done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e1684",
   "metadata": {},
   "source": [
    "#### (optional) display information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8224bb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 distance values before alignment:\n",
      "\t [20.68378689 22.18273096 24.31330916 23.95234415 23.24669574]\n",
      "\n",
      "First 5 distance values after alignment:\n",
      "\t [0.97998441 1.44018644 0.67766133 1.63945315 1.84342085]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e60bd125baf42ce97cbacfd03381c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=49999)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAERCAYAAACgrXoBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4J0lEQVR4nO3df3Rc5XXo/e8+ZzSDME4dJk5VAw6QEhqv+gaBcaP8cCfXxOAUglvdt4VwM1xsoiXHOFFC4xe/982qutJKCU2CSqGOFGzHupeSdRtTAymEH64FJprGNpapIYQE0sY44OIo8QshaKSZ2e8fM+cwM5qRJXk0c0ban7VmWZpz5ugcyXP2PM+zn/2IqmKMMcZUg1PrEzDGGDN3WNAxxhhTNRZ0jDHGVI0FHWOMMVVjQccYY0zVWNAxxhhTNRZ0jDHGVI0FHWOMMVVTk6AjIttE5FUReabo+c+JyLMi8oyI3CMip+Wev0JEnheRF0TklqLXXCMiB0Wko4qXYIwxZhpq1dL5FnBF/hMichbwGWCZqv4+4ALXiIgL3AmsBpYA14rIkryXXgNcCrxfRM6owrkbY4yZplAtfqiqPiEi55bYFAIaRWQMOB14GVgOvKCqPwUQkW8DVwM/zL1GvMPmfe0TkTagLfftJZW6hiA6/fTT+c1vfuN/H4lE+O3f/m3S6TTz588H4Pnnn0dVERHmzZtHJpNh/vz5vPrqq/7zv/Vbv0VDQwPRaJR58+Zx/PhxTpw4wYIFC1i4cCFvvPFGwXEuvPBC5s2bV5FreOONN3j99ddxXdc/70odO8ieeuopLrlkVv/3NHXsqaee+oWqLqzIwVS1Jg/gXOCZouc+C/waOA7cnXvuvwF35e3zSeCOvO+vB4aAmyfxM3UuPkREXdfVd77znVN6XTgc1k2bNhU819vbq11dXeo4jn/sVatW6eDgoKqqDg4OaldXl/99vom2edsbGxv9YzuOo42NjWX3n02yb0Vjggk4oBW699ekpVOKiLydbAvmPOAE8I8i8t+BZInd/SqlqroD2FGNc6xXqko6nebVV1+d0uvGxsa49957C57bunUrixYtIpPJ+Md+9NFH2bt3Lz09PXR0dDA6Oko4HKanp4fh4WFisRgAK1euZGRkBBHhz//8z/nKV75ScOyBgQFGR0f9Y2cyGUZHRxkYGPC3x2IxWlpapvFbMMZMRSKR8N9zFVWp6DXVB0UtHeD/ArbmfR8H/h5oAR7Oe34zsHmaP7PmrY56eoRCoXEtnVAopCJScv/3vve9/jbHcbShoUFd19XGxkZtb28f97re3t6CT1PlWjq9vb3a2NjoH2s2tnywlo4JiMHBQW1vb9dIJOK/54DndLa1dIAjZJMBTgfeBFYCB4D9wAUich7wc7KJA5+o2VnOIarKu9/9bn98BSCVSpXd/7nnnvO/zmQy/n+ykZERjh07Nm7/v/mbv2Hp0qXAW62Y3bt3MzAwQDQaZXh4mGg0ytatWxkZGUFV/ZZPS0tLwScxa/0Yc+oSiYTfI6HZD+qMjIwARCv2QyoVvabyAO4BXgHGgKPAutzzfwn8CHgG+F9AJPf8x4AfAy8C/3O6P3fBggU1bz3U2+Nd73rXjLem8j9R5Y8Ntbe3aygUKtg/HA7r4OCg3yqaLa0frKVjAqCrq0td1y31Xs1oPbd0VPXaMs//BfAXJZ5/EHjwVH/uvHnzOHHixKkeZk752c9+NqPHT6VSfutpZGSEW2+9laamJrZv387o6Kj/acuzdu1aWlpa6O7uZnR0lHQ6XdD6McZMXywWIxwO++89b3y1koLUvTbj5s+fj+M4M/KLNKdOVdm1a1fZ7ZFIhHg8DhS+OcLhcOUHO42Zg1paWti9ezf9/f3cddddFnRO1bx587jssst45JFHan0qZpIikQirV6+mqamJeDzut2a8N4eN6RhTWS0tLQwMDPi9DCKCqv6iUseX4u6L2aypqUn/8z//s9anYSbJdV1uvvlmFixYMOsDS+6NXevTMAZ4K6HA60l48803f6Sq763EsedU0Mml7Jo6ISK4rouqEg6H2b1796wNPBZ0TNDkZ4d+4AMfeEpVl1XiuHOqe83UFxEhk8lMapKopU8bU1ktLS0z8l6ylo4JrLPPPpvjx48zNjYGwOLFi3nppZfIZDI0NDQUzNfJ7wqoxxaRtXRMkIlIxVo6c2o9nTPOOAORcTVBTUAdPXqUZDLpp27+x3/8B+l02p8k2t/fD7xVPic/fdoYE0xzqnvt17/+dcHselMfTtYCsPRpY05dcRf1TNVes+41U5dCoRBPPPGE34020RumHrrarHvN1FJxF3Vx8d5KZq/NqZYO2Jt7tjjrrLMA6O7u9gNLfgCq9zEeY6qpuIt6586dBd8D8yv1s+ZU0LGAM3v87Gc/4yMf+QipVGrcMgoDAwMkk0kymQzJZNIKhBpzEsVd1K2trezduze/pfN6pX7WnAo6FnBml2Qy6f970003kclkCIfDbNy4sWBNnmg0aq0fYyZQqsLH0qVL8+fpvFGpnzWngo6I+HM/zOwhIqRSKVSVZDLJoUOHClq1Q0NDDA8P+90FIyMj9Pf3W9AxJs9MzcspNqdSpi+88EL+6q/+it7eXs4444xan46pkKVLl/oBJn9FU8/WrVuJRqO4rutv2759O4lEovona0wd8HoGvvjFL7Jy5UqAeZU69pwKOvPmzWPz5s20tbVx2WWX1fp0TIX86le/Kvj+0UcfLfg+lUoxPDzM2rVr/XlaY2NjNp/HmDKKEwuoYCLBnAo6+TZt2oTjzNnLn1WK1/wpHrtraGggFovR3Nxc0CKKRiu3GKIxs4mXWOC6LuFwGKBiiQRz8q7rZTG9+93vrvWpmBkkIixfvtzPXhseHvY/aDiOw/DwcI3P0Jhg8hILvvSlL7F7924ASySYLq+v0kupNbOHlyjiiUQi9PT0+IOjsViMSCRilQuMqaE5F3S8vkoLOLNLKBTiggsu4Cc/+QnpdBoRYePGjQXZOLbwmzGTUzzFgAomEsy5oOP1VVpLZ3ZJpVI899xz/veqyte+9jXWrFkzLvBYsDFmYpZIUEHep13LXpv90um0X4naGDN5lkhQYS0tLXR2dtLY2IjjOLiuy0UXXWTZbMYYw8wmEsypKtPLli3TAwcO+N97WWzRaJSOjg7efPPNGp6dqbTiStRBZnUBTZDZIm4V0tLSwubNm/0SKWZ2sZu4McEzp4OOJxaL+SVSzOyRyWTo6Ohg/fr1VvLGmICwoEO2xbN27dqC52xZ6/rjOA7XXXcdoVDI767at28f3/jGN/jIRz5igceYALCgkxOPx/3EAsdx/ImGjuP4C4aZYMtkMsyfP58nnniCj370owUfHEZHR63WmjEBUJOgIyLbRORVEXkm77lzRGSPiDwnIs+KyGfztl0hIs+LyAsickvRsa4RkYMi0nEq5+Rla7S1tQHZG5iqkslkOHbsmGW21Yljx47R0tJCa2trwd/MKhAYEwy1upN+C7ii6LkUcHNuHe73AxtEZImIuMCdwGpgCXCtiCzJe901wKXA+0XklNYr8LKciieNptNpm0haJ5qamkgkEnR0dKCquK7LmjVr2LNnT11ksRkz29Uk6KjqE8Avi557RVUP5r5+HXgOOAtYDrygqj9V1VHg28DVeS/1+lA07+uKikQihEJzrnhD3RER4vH4uFJHy5cvt4BjTEAEss9IRM4FmoEfkA08L+VtPpp7znMvcAA4kAtWxcdqE5EDInLg+PHjJ/3Z8XicSCSCiNDQ0EB7ezt79uzhyiuvPIUrMtXwvve9Dxg/m9q61YwJjsB9fM91ke0EOlT1NSmdRuZPwFDVHcCOcsdT1T6gD7KTQ0/281taWtizZ8+4opBNTU1TuxBTdYcOHeLDH/4wf//3f2+FPY0JqEC1dESkgWzAuVtV7809fRQ4J2+3s4GXZ/I8vEmj+Ter/BbQVNKpc3WLTJWk02k2bNjA4cOHx21LJBJ0d3db6rQxNRSYlk6uRbMVeE5Vv563aT9wgYicB/ycbOLAJ6p9fvktoBMnTnDrrbee9DWhUIh3vetd/OQnP6nCGRpPKpVi/fr1QHY8Llc7qqBU++7du60FZEwN1CToiMg9QAx4h4gcBf4CeB74JHBYRA7ldv1/VPVBEbkJeBhwgW2q+mz1z3p8WfyvfvWrQHZSYiqVGrd/KpU6pYBz7rnncvTo0ZLHNhPzkghGRkb8+Tn5pdq91USNMdVVk6CjqteW2VSy30pVHwQenLkzmrqvfOUrrFmzpmTLx3EcVHXKtb9CoRCqSjqdBuCVV17h85//PF/72tf858zEQqFQQZBWVU6cOMGaNWsIh8O2aqgxNRaoMZ164439LFiwoGAiYiaT8SsbTMaKFStob2/nzjvv5JJLLvHHjLxP5Fa4cvJKtQoPHTo0rlS7tXKMqY3AjOnUA28phPyMqEQiwZEjR3Bdt2ACqaqyaNEijh49OuExV6xYwZe//GVuvfVW1q9fP+4YBw8enNa5Wqn8t7S2tgK2aqgxQTCn19OZiuI1w4sHp4FpdYF5dd7KvXY6XXVr1qwBYNeuXVM+n9lARPjEJz7B8ePHaW1t9UsbBZl9SDBBVsn1dKylM0nFa4YXD047jkMoFPJrtuXfQBYuXEi5ianlyut4Sy2US1Iop729nS1bttDX1zdng46q8o//+I9+skCpFqoxpjYs6ExSLBbzg0ooFPIHovMHp3t6ehgeHmbfvn0FN/wPfvCDPPDAAwWtmYk+2TY0NHDHHXcwPDxMNBpl48aNk15k7m1vexvr16+fdrfcbDE2NkZnZyetra10dHRYqrQxAWFBZ5IOHz5MKpUqaMW0tLTQ09PDzp07C7pxEokEDz30kH+j27RpE5s2beKWW25h7969JYPNihUrOPPMM2lqaiIejxfcGJcuXUp/fz8Azc3NDA0Ncdddd41rATmOY5luOarKY489xp49e/yCrZYqbUztWdCZgNctE41Guemmm/ybeSqV8rvXvE/Re/fuZenSpf5g9e233+4HI+8mt2TJEp544gmgcCllEeGKK65g8+bNJc/De31/fz9DQ0PE43Hi8Ti33HKLfzyPBZy3eF2X3riZpUobU3sWdMrITxwoHuh3HIdYLFZynMcbQygVjMrxjjfRucRiMb+Lbfv27dx+++08+eSTBfstXryYn//854yNjZ3axc8ikUjE7/a0MR1jas+CThn5AcVLEkin07iuyx133OHfvEpNOCwXjOLxONu3byeZTBb8rKuuumrCm+HAwEBBIBkdHWXnzp3jkhCOHDliy2zncV2Xnp6eusheM2ausKBThlcevzhJIP/TsjfhsDgzqvi1XjDy6rf19/dz1113kU6naWhoYPXq1XR3d4+b/+N17XnzgLwxnHA4TGtrK3v27CkIRrbQ3HjDw8OWvWZMgNg8nQmcys3qZK/NDyrF2VWQnf+TTCb96gZecMpPNOjr6yuYUOo4jgWeHMdx/K61eshes3k6Jshsnk6VnMoM9pO91tvW2dnpB5fi+T9eAMlkMoyNjbF8+XI/2SCRSDA0NITruqgqIsKHPvQhBgcH/W5AEZmT4zsiguM4fuvUCn0aExwWdGogkUjQ39/Ptm3bSKVSfmsmvysuHA4zMjLif/rNZDJEo1H6+vrYunUrQ0NDfgo3ZLPh9u7dSzgc5sYbbyQej3P48GG2bt3KokWLWL16NRs2bJgTFau9tHavO9QKfRoTHBZ0qszLissPKI7jcNlll9HZ2el/Ct+9ezednZ08+uijqCqO4/DQQw9NWGVAVUmlUixevBh4K5378OHDrF69mosvvph9+/bN+DXWWn56dLlxN2NMbVjQqYCpjP14mW1ewBERIpEIra2tftea1zXX2dnJ3r17GR0dJRQKsX///nHHc12XD37wg/zrv/4r6XTav9nmZ9CNjIzw6U9/uuwcnoULFzJv3jyOHDlS92NCjuPQ1tZWMMHWCn0aEyBeV8RceFxyySVaaYODg9rY2Kiu62pjY6MODg5Oev9IJKLt7e3a29tb9hiDg4Pa3t6u4XBYgYKH4zjqOI42Njbqpk2bdNWqVdrb2+u/rtRrih+u6550n3p6rFixouJ/42rIvhWNCSbggFboPmzr6ZyicoVAy8lf12XPnj1s2bKl5GB3/v6LFy8uGIsREVasWIGIkMlkSCaTfP3rX+exxx7j05/+NH/8x38MwNq1ayectyMinHPOOad0/UFz5plnkkgk6O7uJpFI1Pp0jDFFrHvtFE1noLq4u2eiY3jr9eQHDxFhyZIl7N+/n9HRUb8Stea67Hbt2sVDDz3E7bffzmmnncabb75Z8jxUlZGRkeldeEA98MADfPe73yWdThMKhVi3bt24WnbGmNqxeToVUInJh+UWiPNK8XhzcFTVn38yNDQEZIuA3nTTTQXp0SLCX//1XxOLxejo6JgTCQTlNDY2BnZ+jsfm6Zggs3k6AVOJgepSx8jvulNVli1bxsUXX0xzc3PBhMd4PM4dd9xRkCzgui5HjhwBYN26dTz11FNzthiozc8xJjgs6ASY1+3mTR49cOAAhw8fBhg3BhSLxbjqqqu4//77yWQypFIp+vr62LZtG6o6ZwNO8fwnY0xtWSJBgHnr9Zx//vl+0oBXaToUCiEihEIhotEoK1eu5L777itIefb2n4tVCSDb2mtrawt815oxc4m1dAKouC5bMpn0J4iGw2Gam5u56667/BbM0NBQwdwfk5XJZFi8eHFBwLHin8bUlgWdGiu+CRav45PJZMhkMogIy5Yto6enh/7+fj+FOpVKcezYMX/pBfMW13XHZQJ6v9sgF/80ZjazoDMDJvtputRNsL+/3y+R4614Cdn05qeffrrssayVM96NN95Y8Psvt86RMaZ6bEynwrxA8sUvfpGVK1dOOEGx+CboFQH1AkhDQwNXXXWVH3i8ZbLj8TiRSMQvodPU1OS3chzHYfny5Zx77rkFP6uxsXFmLjhgQqEQruvS2NhIPB4v2OYlZriua8kFxtSItXQqbCqfposnhQJ+8BARbrjhBuLxOA8//HDBxFFvMTivNQWwY8eOggXnAFasWOF3w3kJCLPdlVdeyfLlywu6K/NbnVb805jasqBTYVOpUFB8E4TC4OHNpO/p6WHnzp20trYC+KuMemvrAH7XXP6xr7zySr8qdb0X8pyORCJBLBZjbGyMhoYG/wOABRtjaidQFQlEZAFwF/D7ZAs4rlXVhIhcAfwt4AJ3qeqXc/tfA2wC+lW152THn6mKBMUqteIoQH9/P9u3byeVSvmz1vOrEnhrxgAF40M9PT185jOfIZlMAtmuuvxSObOVt6id4zh84AMf4IknnvC3tbe3s2XLlhqeXXlWkcAEWSUrEtS88nP+A9gB3Jj7OgwsIBtoXgTOzz33NLAkt8+u3PZvA2ec7PgzUWX6VA0ODmpXV9e46tReNWoRKVlNWUQ0FAr5lanb29v9itGu6+qqVav870VE16xZo47j1LwKdDUfxb+79vb2Gv2VTw6rMm0CjApWmQ5M95qIvA1YAfwPAFUdBUZFpAV4QVV/mtvv28DVwA8Brwqm5n1dfNw2oA3wFzcLiolSePOz2ErJT6f2xmvyu/VaW1v9tXjC4TBNTU1Vu66g0FyLx/u3ubm51qdkzJwXpOy184HjwHYRGRKRu0RkHnAW8FLefkdzzwHcCxwgG4VfL3VQVe1T1WWqumzhwoUzePpTV25ZhEQiwfbt2wsCjuM4NDQ0+P9ee+21OI7jTxiNx+P+kgm7d+/2Z+J738fjcUKhwHzGqBrvd6SqdHR02HIHxtRYkO5CIeBiYKOq/kBE/ha4Bfi3EvsqgKruINslV5fKJR0MDAwUrJ8D2ZbNunXrWLx4sV+pIJPJ4LouPT09BatkQjZw9ff3c+zYMY4cOUI8Hmft2rV84xvfqOo11kJTUxPHjh0D3soGVFWbm2NMAAQp6BwFjqrqD3Lff4ds0HkQyF9p7Gzg5Sqf26RMNYGgXApvLBbDdd2CuTde+Zvh4WG/7I1XqWB4eHjceXzkIx/xkwgAtm/fzu23304oFBoX0Gab48eP+197iQWqanNzjAmAwAQdVT0mIi+JyIWq+jywkuy4zX7gAhE5D/g5cA3wiRqeaknTLbFSLoVXRPyCnuvWrStYzsB1Xb+rLBwOE41G/TTqlpYWv9su3+joKMPDw3z+85/n1ltvrcxFB1R+OSAvVby4RWiMqY3ABJ2cjcDdIhIGfgrcoKopEbkJeJhspto2VX22lidZSiVLrHjda6rqF63MX9Ia4FOf+lRBV1t+sItGoziOU3DzdRyHZ599lnvuuaci11svvFZOqRahMab6AhV0VPUQMC4XXFUfJNvNFljTWbZ6qsfKf86bOLp+/Xo/yy2ZTNLR0cGhQ4f8rrd3vOMdHD9+nHQ6zd13312Zi60TjuP4hVCta82YYAjU5NCZNtOTQytZNr/c8tXFFamLx27MW3p7e1m6dGldlL2xyaEmyCo5OdSCTsBNFMi6u7v54he/WFCvbS79PScyf/58XnvttVqfxqTZ384EWSWDTqC610yhkyUn5C9n7SUepNPpsjevVatWsXv3btLpNI7jEIlEePPNN6t1OVXlui5gi7YZEzRBmhw65yQSCbq7u8tOWMxPTkgmk3R2do7b9/LLL/c/Jbuuy4c//OGSx1q+fDkPP/wwe/fupauriyeffJJLL7204tcUFG1tbVNaZsIYUyWVqqdTD48g1V7zaqt5tdOKa6/l7+PVTHMcx9+3t7dXQ6FQQW0xx3H0d3/3d8vWa7vuuusKjt/e3l7z+mgz8Tj77LNVVbWrq6ugHl1XV1dV/rbTgdVeMwFGBWuvWUunRsqVwMnnTR697LLLcBzHr7PW39/PTTfdVDDJ06vF9uKLL5btXvuHf/iHgk/7r79esnJQ3Xvb294G2KJtxgSRBZ0amewNsaWlhc7OTiKRiL8vFE6AdF2XSy+9tKC45ZlnnjnuWKrqB7e+vr5Zm0L9nve8B3graHv152xMx5jas0SCGskvgRONRv1gUOrGWG6xt2Qyieu63HHHHSxdupSVK1eSTCbJZDL86le/Gncc13WJRqMAbN26dcaurdZWr15dkECQv9idMaa2LGW6xkplqAEnzbgqN4+ns7OTxx57jEwmg+M4LFu2jNNOO43vf//7ZDIZQqEQn/vc57jtttsYGxur2nVWk1cmKJVKTakkUS1ZyrQJMkuZnkWKM9S8igLeLPr81UHzb5ylarZ5XXH56+j09PQwMDDAk08+iaoyNjbGV7/61WpfZlWl02kymYxVljYmgCzo1JhXUdpbkG3//v3+J96RkRHWr18PQCQSmdQn9nKVq72fAdkimA0NDX42yWzkjW1ZAoExwWKJBDPkZHNwPIcPHy6Y0JkfBDRX8DOTyZBMJktmuJXS0tLij2N0d3cD8LnPfa5gnz/90z/1J1DORiLC+eefb5WljQkYa+nMgMkuc5BIJNiwYUNBJlo5ruuW/cTuje9Eo1G/Kw4oOIfrr7/eT7t2HIfjx4/P2lYOZAP2Cy+8wMaNG1m6dKkFHmMCwoLODJjsMgcDAwN+lxfgB4V8IuJnqJUq/AkUZK155W2uv/56/xxGRkY4duwYkUjED0Ktra38y7/8y8z9Empo3rx5vPHGGwD+vCYLOsYEgwWdGTDZZQ5isRiRSIRkMonjOPzZn/1ZwdyZUCjEjTfe6C9jAONbUV5wyR+v8RZw88r6qyoPPvign6TQ2trK0qVLx7V03vnOd/Lqq6/OwG+kun7zm9/U+hSMMWVY0JkB5QbzT7bfwMCA39oREW688Ua2bNlS8JriVhTgF/30WjreqqKrV6/mvvvuQ1VJpVLcdtttZDIZ9u7dy+WXXz6uW282BBwoHBdzXZd4PF7DszHG5LOgU2PFqc/5XWClbpbFlaWbm5uJx+P09/dz7NgxAB588EG++c1vEgqFaGhoIJ1O+xWovaSE+++/v2rXWEs333yzda0ZEyA2OXQGTDaRoNxrixdqK24x9fX18elPf5pMJkM4HOb222/3l6z2lqnOZDK4rjtuWeuRkRGAWZ1EkC8cDtfFPB2bHGqCzCaH1tBk1meZbCJBKfktn3LBa2hoyO8aSyaTbN261e9e84KNiBQsaw3w4osvcuutt1bgt1A/xsbG6iLoGDNXWNCZgsm2YCaTSDDV4OWtp9PZ2Tluv/xEAlXl85//PAsWLBh37EOHDk3ruutZQ0ODTQ41JkAs6EzBZFswJ0skmGrw8loxjz32GHv37qWnp4dwOMzY2Biu63L48GH/NSLCggULCopcegHuoosu4pFHHqngbyT4/u7v/s5aOcYEiAWdKZhsKjSUro3mKRe8ils/XvDq7Ozk0Ucf9ZMAhoeHGRgYYGBggCNHjtDX1+cf25tEmj9h1BvvCYfDbNq0iYGBAZ566ik/2w2Y1ATVoPOKfOYbGhqq0dkYY0qxoDMFk02FPplSwatc66elpYXW1la/hZLJZDhx4sSEyxzAW9UIvMXdvPk7CxYsoKenh1gs5o//dHR08K1vfavuU6aLAw7A448/TiKRKFsR4lT/lsaYKarUEqT18AjactVdXV3+MtXFSyu3t7f727u6uvwlq0VEGxoaCpa5nuhYjuOo67oqIhoOh/1987c3NDSUXPa53LLX9fQQkZLLgU9mufBqwparNgFGBZertpZOjRR3v+W3fkKhENu2bStY3sCbv5M/32ZkZIT+/n62bNlS9liu6/qFQ0XE3+5VnfaOly8UCnHllVfywAMP1H23m5ZZ3uBUMgyNMdNnQScg8rvujhw5wje/+U3/hjg8PFywyuhnPvMZkskkqsq2bdsK0qI9119/vf91X1+fv5ZOR0cHixYt8ueEeEtcqyqhUIg/+qM/oqmpCajfuTyO4/Dxj3+cf/7nfyaVShEKhcaNv01lfM4YUzkWdKroZGMIXuunr68PESlYDya/ZTQ0NERvby+qSjqdLviUXjw2tHHjxoK6bPv27Sv4mWNjY34yAWSrGXgVDIqLj9aLTCbDj3/844LlIg4fPlwyScPGdIypspP1vwH3AP83sBpYWKl+vak+gCuA54EXgFvynr8GOAh0nOwYtRzTmewYgrefN9bS29s7pWMVjw2tWrXKHw+aymM2jOd4D+93OdE4WK1hYzomwKjymM43gP8CtALdIvLvQFxVX5/EaytCRFzgTuCjwFFgv4jcr6o/JBt0LgXuFpEzVPXX1TqvqZjKcgfeZE8RYXh4eNw+E31KLx4bOv3002loaGBsbOykyyjkC4VCZDKZuh/TAQrGwbylDnbs2DGtMkXGmFN0sqgEfJJs0Anlvr8O+Hqlot5kHkAL8HDe95uBzbmv7wNcsi2y+SVe2wYcyD1q/qnbHvawhz3q8FGxls5klqt+D/BXwI9EZAhYBfyJiKwUkYWTeH0lnAW8lPf90dxzAPeSCyqlWl+q2qeqy1R12SWXXFKTrkFVZXBwkPb2dtrb2xkcHDzpvl1dXSfdb6JHV1eXvxy167q0t7fT2NiI67o0NjayZs2akr9ox3FobGykt7eXrq4uNm3a5Ge91atwOExvby/t7e2Ew2F/DMu71lP5PVfwg1XNz8Ee9ij3qKTJdK/drqrHAUTk7cAysuM71wFfJtu1NdNK3fUUQFV3ADuqcA7TVjy4f7L1XSaqZjBZxdlZQEH33ssvv1yw//Lly1m3bh3Dw8Pjqhh84Qtf4LbbbitYIqGepNNphoeHWbx4sd/N5jgOl112GZ2dnda1ZkwVTSboPJILNs+RHcj/PeAeVf3sjJ5ZoaPAOXnfnw28XGbfwKnFnJDicR+gYBxj3bp1PP300/73PT09/jl1d3f79d6SySQLFizg8ccfp7+/n4MHD7J///6Kf/qZKV61be93kB+ILeAYU30nDTqq2pwbyP894ELgMeB7M31iRfYDF4jIecDPySYPfKLK5zBttZoTUtxiKk4+WLp0aclkhGg0WpBmHY1GgbfK7dRLwAH48Ic/zJlnnkl/fz/xeNzSpI2psUnN01HVNPBs7lF1qpoSkZuAh8kmDWxT1Zqcy3QEYU5IqTlC5brxhoeH/ew2x3EYHh6mv7+fkZGRugo4AN///vf97sC+vj4+/vGPs2nTJgs4xtSIrRw6B0x1JdPi/Xt6eti4cSOjo6NVPOtT5yVAFP8fj0Qi7NmzJ1CBx1YONUFWyZVDJ5O9ZupcqTGliXgts0996lNcf/31BSuV1gsR4Qtf+IKfRJFvMr8DY8zMsDI4c8B0x5S8xAPXdQmFQicNPF4R0aB8Yn/3u9/Nnj17uPXWW7n//vv9cSqrtWZM7VhLZw7wWi5f+tKXJj37Pr91lE6n+YM/+IMJ5+ssX76cm2++mVAoGJ9jVJX169dz+PBh/umf/oknn3zSnycVtK41Y+YSG9MxJeWP67iuSyqVKlk2x3EcQqEQH/vYx/jud7/rt4aq+f+q1IqhnoaGBh5//PHABxkb0zFBZmM6Zsblt47Wrl1btk7bhRdeiIhw3333kUqlZmQG88lMVEPOq8JtjAmGYPSFmEDyUqoTiQTbt28nmUyO22f+/Pl+sKmV/J9d3GJwXdfGb4wJEGvp1EgikaC7u5tEIlHrUzmplpYW9uzZQ3t7O2vWrKGhocGf6b9u3bqCembT5ThOwTHKHa/4ecdx/BpzpbYHvVvNmLnGxnRqYKrzZmbyPKYzYbX4dd73J06c4N577+WFF16Y9LEWLlzIL3/5S1SVhoYGVq9eTVNTE83Nzf4KqRNZs2YNTU1N/qJ2xXNzRITTTjst8MsX2JiOCbJKjulY91oN1KIWW7FTCXzFlQy8r1euXFkySJS7oYoI5513Hr/4xS9QVVKpFMuXL2fz5s10d3eXTQ7It3r1apYuXeqnd4dCIVSzS3N740sT/Y6nG3iNMdNjQacGalWLLV8lA18ikaCzs9MvEuo4DsuWLWPRokUA3H///eOCjpf1NjQ05G8LhUL+7yL/d6SqZZMFhoaGaGtro6enh507d9La2srSpUvp7+9n+/btpFKpsr/joLQ4jZlTar1OQzUftVyuulitl0ue7PLZkz2OtyS24zgFx+vq6iq5XLbrurpmzRp/aW0R0fb29nHH9n5HK1asKLm4VHt7e9lrOdnvuHhp766urmn9Dioh+1Y0Jpio8nLVZgZUYs2cU/35lShCmr+8dqk1amKxGJFIhDfffLPgdZlMhqampoIWXzweH9fd5R3nuuuu44knnhj385ubm6fdagtCi9OYucaCziwxnbGJmVgsrniNGi+49ff3s3XrVsbGxoBsV1o8Hicejxes+VOuuyu/8rXHq4BdKnhMpussCNW/jZlzKtVkqodHkLrXKqlSXWWn8vMn01XY29urruuqiGg4HB63/0TdXSfrxis+hyB1nU0G1r1mAgzrXjP5ap0NN9kW0/DwMJD9oONVCihePE5EcBxnXHdXfqskGo36LZxyawNZ15kxwWRBZxYI6g3W6/LzgkQ0Gi17nolEgo6ODjKZDK7rFiyf7ZlKd6B1nRkTTBZ0ZoEg3mC9MZX8NOpIJEJPT8+4VgoUJiSIiN8qOhW1TtYwxoxnQWeWCNoNNj+IQDZbbXR0lOHhYTZv3jxu/6C21owxlWVBx8wIL4jkt3QmCiZBbK0ZYyrPaq+ZGVM8pmPBpDyrvWaCzGqvmboQtC4/Y0zt2dIGxhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKoJVNARkQUi8h0R+ZGIPCciLbnnrxCR50XkBRG5peg114jIQRHpqMlJG2OMmbRABR3gb4HvqervAe8DnhMRF7gTWA0sAa4VkSV5r7kGuBR4v4icUe0TNsYYM3mBCToi8jZgBbAVQFVHVfUEsBx4QVV/qqqjwLeBq/NfmvtX877OP26biBwQkQPHjx+fyUswxhhzEoEJOsD5wHFgu4gMichdIjIPOAt4KW+/o7nnPPcCB8guMvR68UFVtU9Vl6nqsoULF87g6RtjjDmZIAWdEHAxsEVVm4E3gFso0Xoh26rJfqG6Q1WbVfVr1TlNY4wx01XToCMiG0TkkIgcAl4GjqrqD3Kbv0M2CB0Fzsl72dm5fY0xxtSZmgYdVb1TVS/KPV4GXhKRC3ObVwI/BPYDF4jIeSISJps4cH+NTtkYY8wpCFqV6Y3A3bng8lPgBlVNichNwMOAC2xT1WdreZLGGGOmJ1BBR1UPAePWbFDVB4EHq35CxhhjKipIiQTGGGNmOQs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqpetARkW0i8qqIPJP33DkiskdEnhORZ0Xks0WvuUJEnheRF0TklrznrxGRgyLSUcVLMMYYM021aOl8C7ii6LkUcLOqvhd4P7BBRJYAiIgL3AmsBpYA13rbgGuAS4H3i8gZVTh3Y4wxp6DqQUdVnwB+WfTcK6p6MPf168BzwFm5zcuBF1T1p6o6CnwbuDq3TbxD5H1tjDEmoAI3piMi5wLNwA9yT50FvJS3y1HeCkj3AgeAA7lgVep4bSJyQEQOHD9+fGZO2hhjzKQEKujkush2Ah2q+pr3dIldFUBVd6hqs6p+rdwxVbVPVZep6rKFCxdW/qSNMcZM2owHHRHZICKHco9FE+zXQDbg3K2q9+ZtOgqck/f92cDLM3O2xhhjZtKMBx1VvVNVL8o9SgYLERFgK/Ccqn69aPN+4AIROU9EwmSTB+6f2bM2xhgzE2qRMn0PkAAuFJGjIrIO+CDwSeC/5rWKPgagqingJuBhsgkG/0dVn632eRtjjDl1oWr/QFW9tsymstlnqvog8ODMnJExxphqCVQigTHGmNnNgo4xxpiqsaBjjDGmaizoGGOMqRoLOkUSiQTd3d0kEolan4oxxsw6Vc9eC7JEIsHKlSsZHR0lHA6ze/duWlpaan1axhgza1hLJ8/AwACjo6Ok02lGR0cZGBio9SkZY8ysMudbOolEgoGBAWKxGLFYjHA47Ld0YrFYrU/PGGNmlTkddEp1p+3evdsPQta1ZowxlTWng06p7rTNmzdbsDHGmBkyp4POVLvT8rviAPr7+wGIx+MWqIwxZhJEVWt9DlWzbNkyPXDgQMFz+YGkOHAUB5lYLMbY2BihUDZWj42NARAOhxkYGLDAY6ZNRJhL70VTX0TkKVVdVoljzemWDkBLS0vJYFE83nP55ZczOjoKvBVsPGNjYxZ0jDFmEixluoyBgQGSySTpdJpkMsnLLxcuBZRdAiiroaFhXNecTTI1xpjx5nxLp5xoNEomkwEgk8kQi8V4+umnGR0d9btBXNflqquuYtOmTQWtnJNNMvW67aLRKMPDw5YpZ4yZMyzolDE8PIzjOGQyGRzHYcGCBezZs4fOzk4ee+wxPyAtX77cDxiJRIL+/n4OHjxIMpkkk8n4WXH5+6xcudLf7jgOoVCItWvXWkKCMWbWs6CTp3iiaCQS8Vsr0WiUgYEBWltb2bt377iMt0QiQSwW88d9ABzHGZcV56Vp57eiRkdH6e3tZceOHVZ6xxgzq1nQ4a0Wyvbt20mlUoTDYXp6erj++usBaG5upqOjww80Gzdu5NChQ7S2tgLQ3d3NkSNHCgIOwLJly1i0aBH9/f3s2rWLgYEBTjvtNFzXRVXJZDJ+1pKqjmsVeec21cmq03mNMcZUw5wPOl5318jIiD9Wk0wm2bBhA6pKOBwG8CeRJpNJbrvtNjKZDI8//jiqSjqdLnnsffv2lXzedV3a2tpobm7moYce4r777kNVcRyHaDTK+vXrgfHBzmsFnSzN24qWGmOCas4HHa+7yws4IoLruqRSKVSVZDLJsWPHEBG/VeKlTHtdZFOdX+EFqaGhIR544AH/9WNjY7S3t/vfO47jt4KSySSdnZ20trbS0dFBMpnEcRzuvPNO2traxl1PfpWFcinhp9IastaUMWZavJvaXHhccsklWmxwcFAbGxvVdV0Nh8Pa3t6umzZtUsB/OI5T8L33cF237LaJHiKiIjLl1zmOo6FQqOC1DQ0NOjg4WPJ6GhsbC7ZNZZ+JnOrrzXjZt6IxwQQc0Ardh22eDnD99dfzqU99ioGBAbZs2cJrr71WsN1r0RRLp9Nlt03E++VPVSaT8ceB8s8hfwmGlpYWdu/ezZe+9KWyXWunuoSDLQFhjJmuOd291tfXx4YNG8hkMkQiEeLxOIlEgscff7ym5+U4Dh/60Id48sknxwW1SCTCxo0bue2220in00QikXETUyeqsuDNDzqVJRyi0ajf9WdLQBhjpmLO1l5LJBL84R/+oT8+4zgObW1tbN26dVyZm2r7nd/5Hc455xySySRPP/20//ySJUtYsWIF8XgcoGCC6ckmmhYnGPT09BTsP9kxmvx5RqXGlPL3szGfybPaaybIrPZaBQwMDBRknYkIx44dq3nAAXjllVd45ZVXxj3/k5/8hOeff96fzxOLxQommooIDQ0NfndX/k2/uEtseHiYzZs3A1PLeMufZyQiDA8Pj9vHMuiMMeXM2aATi8VwXbeg+2poaKiGZ3RyXkbdyMgIHR0dXHzxxQUTTTU31+eWW25h//79BTf9WCxGKBQik8kQCoWIxWJ+a8SbY3SyjDeY3HIQk82gM8bMPXM26AAFLZ10Os3PfvazGp7NyXndL6rKvn372L9/P44zPhdk7969/r4jIyN+iyf/9YcPH/bnAIVCIVzXBbItvl27dhGNRkt2m3mJChN1ncViMRzHIZ1O4ziOjfkYY3xzNugMDAxMK/MsSDQ3MbWpqYljx44VPJ//9fe+9z2OHDlCOp32X7Nz506/NZLJZLj66qsB2LVrF/v27fMntpYLPBO1XA4fPux3U46NjXH48GFr6RhTZ4rXE6uYSuVeT/YBbANeBZ4pev5zwLPAM8A9wGl5264AngdeAG7Je/4a4CDQMZmfnT9PZ3BwUF3XnfJcmSA+RKRgvlCpuUPhcFgjkYg/t6a3t1cjkUjB9uXLlxe8ZtWqVVNJ5fetWrWqIseZS7B5OiZAiufiAc9pHc/T+RbZIOITkbOAzwDLVPX3AZdsQEFEXOBOYDWwBLhWRJbkXnoNcCnwfhE5Yyon0dLSws0333wKlxEcqurP3XFdl2uvvXbcPul0mhtuuMGfv9PW1sYNN9zgvy6dTrNo0aKC13i15aaq+HXTPY4xpjaKx2WB+ZU6dk1SpkXkXOC7uQDjBZ1/Bd4HvAbsAm5X1UdEpAXoVNXLc/tuBlDVbhG5D/gT4H8Dbar6eomf1QZ4fUS/T7Yl5WkCzsr7fgxoqNBlVpMCkvf1y0AKeAdwet7zPwbeyHvdPOA9udd62xuBtwO/An5xCuf0jgodp/iYlTpW0MzmawO7vnpTfG9IqurpE79kcgIxpqOqPxeRrwJHgDeBR1T1kdzms4CX8nY/CvxB7ut7gQPA/y4VcHLH7gP6AETkgFYo1zyI7Prq12y+NrDrq3cicqBSxwpEGRwReTtwNXAesAiYJyL/3dtc4iUKoKo7VLVZVb9WnTM1xhhzKmY86IjIBhE5lHssKrPbZcC/q+pxVR0j24L5QG7bUeCcvH3PJtt9ZIwxps7MeNBR1TtV9aLco1ywOEI2GeB0yY5srwSey23bD1wgIueJSJhs8sD90zydvmm+rl7Y9dWv2XxtYNdX7yp2fVVPJBCRe4AY2YG3/wT+QlW3ishfAn9GdgB8CLhRVZO513wM6CGb1bZNVf+6qidtjDGmIuZUwU9jjDG1FYhEAmOMMXODBR1jjDFVY0HHGGNM1cyaoCMi20TkVRF5puj5z4nIsyLyjIjcIyKn5W27QkSeF5EXROSWvOevEZGDItJRxUsoq9S1icg5IrJHRJ7LXd9ni15TF9dWTEQWiMh3RORHuWtryT1f8npy2wJ9TaXU699nIlP92wX9Wqf6vqu3/6NTvWdW7PoqVcSt1g9gBXAxeYVEyVYz+HegMff9/wH+R+5rF3gROB8IA08DS3LbduW2fxs4I6DX9jvAxbmv55MtYeOdf91cW4lr3UE2c5HcuS+Y6Hrq4ZpKXGPd/n0q+bcL+rVO5X1Xj/9Hp3LPrOT1zZqWjqo+AfyyxKYQ0CgiIbJ1yLy5QsuBF1T1p6o6SvaXdXVuW34ds1IVEaqq1LWp6iuqejD39etk5zV5deTq5tryicjbyL4RtgKo6qiqnmDi64EAX1MZdfn3mcg0/3aBvtYpvu/q7v/oFO+ZFbu+WRN0SlHVnwNeTbdXgP9PJ67p5t20vZpuB7RMTbcgyRVQbQZ+kHuqXq/tfOA4sF1EhkTkLhGZx8TXA8G+plLq9e8zken87er1WoFx77tZ8X90gntmxa5vVgeduVDTTbJLOuwku6bQa97TJXath2sLkW3ub1HVZrIVsW9hguuBwF9TKfX695nIlP92dXytpd53s+L/6AT3zIpdX90Gndlc022S14aINJD9j3+3qt6btymw11Ys/1rJnuNRVfVabN8heyOrm+uZpNl2PZC9prnwtyv3vpst11nunlmx66vboKPBqulWUZO5ttz1bCW7ot/XizYH9tqKlbjWl0TkwtzmlcAPqaPrmaTZdj2o6jHmwN9ugvfdbLnOcvfMyl1fNbMlZvJBdonrV8guxHYUWJd7/i+BH5FdvO1/AZG813yMbPbJi8D/rPU1TOXagA+Rbd7+G3Ao9/hYvV1biWu9iGzf8L+RzYh5ez1fzwTXOauuZzb+7ab6vqu365zqPbNS12e114wxxlRN3XavGWOMqT8WdIwxxlSNBR1jjDFVY0HHGGNM1VjQMcYYUzUWdIwxxlSNBR1jjDFVY0HHmAAQkT8RkdtrfR7GzDQLOsYEQzNwsNYnYcxMC9X6BIyZy0TkPcCdwPuBYRFZoKo9tT0rY2aOlcExpkZEJEJ2LZZPAveRreb7Q2CRqo7U8tyMmSnWvWZM7XyU7LK/LwOvabZS8wjZZX+NmZUs6BhTOxcBh4H3Af8mIu8EXlfVN2p6VsbMIBvTMaZ2XgP+C5AiWyr/L8mO7xgza9mYjjE1IiJnAv8ELAV+BXwb+H/V3pRmFrOgY0yNicjTwH9V1eFan4sxM83GdIypoVwG23wLOGausJaOMcaYqrGWjjHGmKqxoGOMMaZqLOgYY4ypGgs6xhhjqsaCjjHGmKqxoGOMMaZqLOgYY4ypmv8fwIiYnfPWRTcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print RMSD values before and after alignment\n",
    "print ('First {} distances before alignment:\\n\\t'.format(head_frames), dist_list)\n",
    "print ('\\nFirst {} distances after alignment:\\n\\t'.format(head_frames), dist_list_aligned)\n",
    "\n",
    "#generate Ramachandran plot of two dihedral angles\n",
    "ax = plt.axes()\n",
    "r = dihedrals.Ramachandran(u.select_atoms('resid 2')).run()\n",
    "r.plot(ax, color='black', marker='.') #, ref=True)\n",
    "\n",
    "# display the trajectory\n",
    "view = nv.show_mdanalysis(u)\n",
    "view   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12091344",
   "metadata": {},
   "source": [
    "## Part 2: Training\n",
    "\n",
    "#### define neural network model and training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "654153b8",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Auto encoders class and functions for training.\n",
    "def create_seqential_nn(layer_dims, activation=torch.nn.Tanh()):\n",
    "    layers = []\n",
    "    for i in range(len(layer_dims)-2) :\n",
    "        layers.append(torch.nn.Linear(layer_dims[i], layer_dims[i+1])) \n",
    "        layers.append(activation)\n",
    "    layers.append(torch.nn.Linear(layer_dims[-2], layer_dims[-1])) \n",
    "    \n",
    "    return torch.nn.Sequential(*layers)\n",
    "       \n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, align_func, encoder_dims, activation=torch.nn.Tanh(), atom_indices=None):\n",
    "        \"\"\"Initialise auto encoder\n",
    "\n",
    "        :param encoder_dims: list, List of dimensions for encoder, including input/output layers\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.align_func = align_func\n",
    "        self.atom_indices = atom_indices\n",
    "        self.encoder = create_seqential_nn(encoder_dims, activation)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # flatten the data\n",
    "        if self.atom_indices is None: # use all atoms\n",
    "            inp = torch.flatten(inp, start_dim=1)            \n",
    "        else: # use selected atoms\n",
    "            inp = torch.flatten(inp[:,self.atom_indices,:], start_dim=1)\n",
    "        encoded = self.encoder(inp)\n",
    "        return encoded\n",
    "\n",
    "    def xi(self, x, is_aligned=True):\n",
    "        \"\"\"Collective variable defined through the encoder \n",
    "\n",
    "        :param x: np.array, position, ndim = 2, shape = (1,1)\n",
    "\n",
    "        :return: xi: np.array\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(x) == False :\n",
    "            x = torch.from_numpy(x).float()\n",
    "        return self.encoder(x).detach().numpy()\n",
    "\n",
    "# Next, we define the training function \n",
    "def train(model, optimizer, traj, weights, train_atom_indices, num_epochs=10, batch_size=32, test_ratio=0.2):\n",
    "    \"\"\"Function to train an AE model\n",
    "    \n",
    "    :param model: Neural network model built with PyTorch,\n",
    "    :param loss_function: Function built with PyTorch tensors or built-in PyTorch loss function\n",
    "    :param optimizer: PyTorch optimizer object\n",
    "    :param traj: np.array, physical trajectory (in the potential pot), ndim == 2, shape == T // save + 1, pot.dim\n",
    "    :param weights: np.array, weights of each point of the trajectory when the dynamics is biased, ndim == 1, shape == T // save + 1, 1\n",
    "    :param num_epochs: int, number of times the training goes through the whole dataset\n",
    "    :param batch_size: int, number of data points per batch for estimation of the gradient\n",
    "    :param test_size: float, between 0 and 1, giving the proportion of points used to compute test loss\n",
    "\n",
    "    :return: model, trained neural net model\n",
    "    :return: loss_list, list of lists of train losses and test losses; one per batch per epoch\n",
    "    \"\"\"\n",
    "    #--- prepare the data ---\n",
    "    # split the dataset into a training set (and its associated weights) and a test set\n",
    "    X_train, X_test, w_train, w_test = train_test_split(traj, weights, test_size=test_ratio)  \n",
    "    # intialization of the methods to sample with replacement from the data points (needed since weights are present)\n",
    "    train_sampler = torch.utils.data.WeightedRandomSampler(w_train, len(w_train))\n",
    "    test_sampler  = torch.utils.data.WeightedRandomSampler(w_test, len(w_test))\n",
    "    # method to construct data batches and iterate over them\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=X_train,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               sampler=train_sampler)\n",
    "    test_loader  = torch.utils.data.DataLoader(dataset=X_test,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               sampler=test_sampler)\n",
    "    \n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    # --- start the training over the required number of epochs ---\n",
    "    loss_list = []\n",
    "    print (\"\\ntraining starts, %d epochs in total.\" % num_epochs) \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model by going through the whole dataset\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for iteration, X in enumerate(train_loader):\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass to get output\n",
    "            out = model(X)\n",
    "            # Evaluate loss\n",
    "            loss = loss_func(out, torch.flatten(X[:,train_atom_indices,:],start_dim=1))\n",
    "            # Get gradient with respect to parameters of the model\n",
    "            loss.backward()\n",
    "            # Store loss\n",
    "            train_loss.append(loss)\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "            print (epoch, iteration)\n",
    "        # Evaluate the test loss on the test dataset\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Evaluation of test loss\n",
    "            test_loss = []\n",
    "            for iteration, X in enumerate(test_loader):\n",
    "                out = model(X)\n",
    "                # Evaluate loss\n",
    "                loss = loss_func(out, torch.flatten(X[:,train_atom_indices,:],start_dim=1))\n",
    "                # Store loss\n",
    "                test_loss.append(loss)\n",
    "            loss_list.append([torch.tensor(train_loss), torch.tensor(test_loss)])\n",
    "\n",
    "    print (\"training ends.\\n\") \n",
    "    return model, loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cac50a",
   "metadata": {},
   "source": [
    "#### set training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30ad270a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Atoms used in define neural network:\n",
      "     id name type\n",
      "1    2  CH3    C\n",
      "4    5    C    C\n",
      "5    6    O    O\n",
      "6    7    N    N\n",
      "8    9   CA    C\n",
      "10  11   CB    C\n",
      "14  15    C    C\n",
      "15  16    O    O\n",
      "16  17    N    N\n",
      "18  19  CH3    C\n",
      "\n",
      "Input dim: 30,\tencoded dim: 1\n",
      "\n",
      "Autoencoder:\n",
      " Sequential(\n",
      "  (0): Encoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=30, out_features=20, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=20, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=20, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=20, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def set_seed_all(seed=-1):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "#All the parameters are set in the cell below. \n",
    "seed = None \n",
    "if seed:\n",
    "    set_seed_all(seed)\n",
    "    \n",
    "#set training parameters\n",
    "batch_size = 10000\n",
    "num_epochs = 500\n",
    "learning_rate = 0.005\n",
    "optimizer_algo = 'Adam'  # Adam by default, otherwise SGD\n",
    "#dimensions\n",
    "\n",
    "train_atom_selector = \"type C or type O or type N\"\n",
    "train_atom_ids = u.select_atoms(align_selector).ids \n",
    "train_atom_indices = train_atom_ids - 1 # minus one, such that the index starts from 0\n",
    "\n",
    "#input dimension\n",
    "input_dim = 3 * len(train_atom_ids)\n",
    "print ('{} Atoms used in define neural network:\\n'.format(len(train_atom_ids)), atoms_info.loc[atoms_info['id'].isin(train_atom_ids)][['id','name', 'type']])\n",
    "\n",
    "# encoded dimension\n",
    "k = 1\n",
    "e_layer_dims = [input_dim, 20, 20, k]\n",
    "d_layer_dims = [k, 20, 20, input_dim]\n",
    "print ('\\nInput dim: {},\\tencoded dim: {}\\n'.format(input_dim, k))\n",
    "\n",
    "activation = torch.nn.Tanh()\n",
    "encoder = Encoder(align_functor, e_layer_dims, activation, train_atom_indices)\n",
    "decoder = create_seqential_nn(d_layer_dims, activation)\n",
    "\n",
    "ae_model = torch.nn.Sequential(encoder, decoder) \n",
    "\n",
    "print ('Autoencoder:\\n', ae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80852277",
   "metadata": {},
   "source": [
    "#### start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3751a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training starts, 500 epochs in total.\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "10 3\n",
      "11 0\n",
      "11 1\n",
      "11 2\n",
      "11 3\n",
      "12 0\n",
      "12 1\n",
      "12 2\n",
      "12 3\n",
      "13 0\n",
      "13 1\n",
      "13 2\n",
      "13 3\n",
      "14 0\n",
      "14 1\n",
      "14 2\n",
      "14 3\n",
      "15 0\n",
      "15 1\n",
      "15 2\n",
      "15 3\n",
      "16 0\n",
      "16 1\n",
      "16 2\n",
      "16 3\n",
      "17 0\n",
      "17 1\n",
      "17 2\n",
      "17 3\n",
      "18 0\n",
      "18 1\n",
      "18 2\n",
      "18 3\n",
      "19 0\n",
      "19 1\n",
      "19 2\n",
      "19 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3639/3260436674.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m ae_model, loss_list = train(ae_model, \n\u001b[0m\u001b[1;32m      8\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                             \u001b[0mtrajectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3639/2135367564.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, traj, weights, train_atom_indices, num_epochs, batch_size, test_ratio)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Evaluation of test loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;31m# Evaluate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "if optimizer_algo == 'Adam':\n",
    "    optimizer = torch.optim.Adam(ae_model.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(ae_model.parameters(), lr=learning_rate)\n",
    "\n",
    "ae_model, loss_list = train(ae_model, \n",
    "                            optimizer, \n",
    "                            trajectory, \n",
    "                            np.ones(trajectory.shape[0]), \n",
    "                            train_atom_indices,\n",
    "                            batch_size=batch_size, \n",
    "                            num_epochs=num_epochs\n",
    "                            )\n",
    "\n",
    "#--- Compute average train per epoch ---\n",
    "loss_evol1 = []\n",
    "for i in range(len(loss_list)):\n",
    "    loss_evol1.append([torch.mean(loss_list[i][0]), torch.mean(loss_list[i][1])])\n",
    "loss_evol1 = np.array(loss_evol1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6654229",
   "metadata": {},
   "source": [
    "Plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24567d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_to_file = False\n",
    "start_epoch_index = 1\n",
    "fig, (ax0, ax1, ax2)  = plt.subplots(1,3, figsize=(12,4)) \n",
    "ax0.plot(range(start_epoch_index, num_epochs), loss_evol1[start_epoch_index:, 0], '--', label='train loss', marker='o')\n",
    "ax0.plot(range(1, num_epochs), loss_evol1[start_epoch_index:, 1], '-.', label='test loss', marker='+')\n",
    "ax0.legend()\n",
    "ax0.set_title('losses')\n",
    "\n",
    "if save_fig_to_file :\n",
    "    fig_filename = 'training_loss_%s.jpg' % pot_name\n",
    "    fig.savefig(fig_filename)\n",
    "    print ('training loss plotted to file: %s' % fig_filename)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "ipynb,auto:light",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
